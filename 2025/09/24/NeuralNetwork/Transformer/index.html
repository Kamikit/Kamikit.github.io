<!DOCTYPE html><html lang="cn" theme-mode="dark"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Transformer | Kamikit's Blog</title><link rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="preload" as="font" crossorigin="anonymous" href="/font/Bender.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/BenderLight.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/font/JetBrainsMono-Regular.woff2"><link rel="stylesheet" href="/css/arknights.css"><style>@font-face {
  font-family: Bender;
  src: local('Bender'), url("/font/Bender.ttf"), url("/font/Bender.otf");
}
@font-face {
  font-family: BenderLight;
  src: local('BenderLight'), url("/font/BenderLight.ttf");
}
@font-face {
  font-family: 'JetBrains Mono';
  src: local('JetBrains Mono'), url('/font/JetBrainsMono-Regular.woff2') format('woff2');
}
</style><meta name="page-config" content="{&quot;code_fold&quot;:null}"><script class="pjax-js">var config = {"root":"/","code_fold":15,"search":{"preload":false,"activeHolder":"Enter here","blurHolder":"Search","noResult":"Data \"$0\" not found"},"code":{"codeInfo":"$0 - $1 lines","copy":"copy"}};
var page_config = {
  code_fold: null
};
function updatePageConfig() {
  var newPageConfig = document.querySelector('meta[name="page-config"]');
  if (newPageConfig) {
    page_config = JSON.parse(newPageConfig.content);
  }
}
document.addEventListener('pjax:complete', function() { updatePageConfig(); });
updatePageConfig();</script><link type="text/css" rel="stylesheet" href="/lib/encrypt/hbe.style.css"><script src="//unpkg.com/mermaid@10.5.0/dist/mermaid.min.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.1/MathJax.js"></script><script>MathJax.Hub.Config({
 menuSettings: {
   zoom: "None"
 },
 showMathMenu: false,
 jax: ["input/TeX","output/CommonHTML"],
 extensions: ["tex2jax.js"],
 TeX: {
   extensions: ["AMSmath.js","AMSsymbols.js"],
   equationNumbers: {
     autoNumber: "AMS"
   }
 },
 tex2jax: {
   inlineMath: [["\\(", "\\)"]],
   displayMath: [["\\[", "\\]"]]
 }
});</script><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lightgallery.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-zoom.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-thumbnail.css"><link type="text/css" rel="stylesheet" href="/lib/fontawesome/css/all.min.css"><script>if (window.localStorage.getItem('theme-mode') === 'light')
 document.documentElement.setAttribute('theme-mode', 'light')
if (window.localStorage.getItem('theme-mode') === 'dark')
 document.documentElement.setAttribute('theme-mode', 'dark')</script><style>@font-face {
 font-family: BenderLight;
 src: local('Bender'), url("/font/BenderLight.woff2") format('woff2');
}
@font-face {
 font-family: 'JetBrains Mono';
 src: local('JetBrains Mono'), url('/font/JetBrainsMono-Regular.woff2') format('woff2');
}</style><style>:root {
 --dark-background: url('https://ak.hypergryph.com/assets/index/images/ak/pc/bk.jpg');
 --light-background: url('/img/bk.jpg');
 --theme-encrypt-confirm: 'confirm'
}</style><script defer src="/js/arknights.js"></script><script defer src="/js/search.js"></script><script defer type="module">import mermaid from '//unpkg.com/mermaid@10.5.0/dist/mermaid.esm.mjs';
window.mermaid = mermaid;
code.paintMermaid();
</script><script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.1/MathJax.js"></script><script>MathJax.Hub.Config({
  menuSettings: {
    zoom: "None"
  },
  showMathMenu: false,
  jax: ["input/TeX","output/CommonHTML"],
  extensions: ["tex2jax.js"],
  TeX: {
    extensions: ["AMSmath.js","AMSsymbols.js"],
    equationNumbers: {
      autoNumber: "AMS"
    }
  },
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]]
  }
});
</script><script async src="//unpkg.com/lightgallery@2.7.1/lightgallery.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/zoom/lg-zoom.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/thumbnail/lg-thumbnail.min.js"></script><script async src="/lib/encrypt/hbe.js"></script><script async src="/js/pjax.js"></script><script class="pjax-js">reset= () => {document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.vercount','meta[name=page-config]'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);reset()})</script><script class="pjax-js">reset= () => {MathJax.Hub.Queue(["Typeset", MathJax.Hub]);document.querySelector('.lg-container')?.remove()
const postBg = document.querySelector('#post-bg');
if (postBg) lightGallery(postBg, {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.vercount','meta[name=page-config]'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);reset()})</script><meta name="generator" content="Hexo 8.0.0"></head><body><div class="loading" style="opacity: 0;"><div class="loadingBar left"></div><div class="loadingBar right"></div></div><main><header class="closed"><div class="navBtn"><i class="navBtnIcon"><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span></i></div><nav><div class="navItem" id="search-header"><span class="navItemTitle"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="Search" spellcheck="false" maxlength="50" type="text" id="search-input"></span></div><div class="navItem" id="search-holder"></div><div class="search-popup" tabindex="0"><div id="search-result"></div></div><ol class="navContent"><li class="navItem"><a class="navBlock" href="/"><span class="navItemTitle">Home</span></a></li><li class="navItem" matchdata="categories,tags"><a class="navBlock" href="/archives/"><span class="navItemTitle">Archives</span></a></li></ol></nav></header><article><div id="post-bg"><div id="post-title"><h1>Transformer</h1><div id="post-info"><span>First Post: <div class="control"><time datetime="2025-09-24T09:19:45.000Z" id="date"> 2025-09-24</time></div></span><br><span>Last Update: <div class="control"><time datetime="2025-09-25T06:34:40.032Z" id="updated"> 2025-09-25</time></div></span></div></div><hr><div id="post-content"><ul>
<li>参考文章；<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/2401_85375298/article/details/144106338">https://blog.csdn.net/2401_85375298/article/details/144106338</a></li>
<li><a target="_blank" rel="noopener" href="https://zybuluo.com/hanbingtao/note/2600518">https://zybuluo.com/hanbingtao/note/2600518</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zybuluo.com/hanbingtao/note/2600833">https://www.zybuluo.com/hanbingtao/note/2600833</a></li>
</ul>
</li>
</ul>
<h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><ul>
<li><p>注意力机制的核心，就是提升关键信息的权重，降低非关键信息的权重，通过给每个信息赋予不同的注意力权重，达到聚焦关键信息，忽略非关键信息的效果。</p>
</li>
<li><p>举个例子，同样的单词在不同的上下文中，其含义是不一样的：</p>
<ul>
<li>The animal didn’t cross the street because <strong>it</strong> was too tired.</li>
<li>The animal didn’t cross the street because <strong>it</strong> was too narrow.</li>
</ul>
</li>
<li>我们希望每个 token 能够根据上下文的不同，分配不同的注意力权重，即 <strong>Self Attention</strong>。其核心是序列中的任意两个 token 之间都计算注意力权重，也就是每个 token 都要注意自身及序列中的其他 token，因此叫做自注意力机制。</li>
</ul>
<h4 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self Attention"></a>Self Attention</h4><ul>
<li><p>具体计算过程如下图所示：<br class='item-img' data-src='../../images/Transformer/1.png'><img src="../../images/Transformer/1.png" alt=""></p>
</li>
<li><p>第一步，序列在输入之前，首先要将 token 转换为向量，按行拼接成矩阵 X。随后，token 向量矩阵分别右乘三个可学习的参数矩阵 <script type="math/tex">W_Q、W_K、W_V</script>，得到 Q（Query）、K（Key）、V（Value）矩阵，其中 Q 和 K 中的向量维度是相同的，而 V 的维度可以与 Q、K 不同。</p>
</li>
<li>第二步，计算 token 之间的注意力权重，具体做法就是将自身的 Q 矩阵与序列中其他所有 token 的 K 矩阵相乘，即为当前 token 对序列中其他 token 的注意力。若向量的维度较大，则最终的点乘结果也会显著增大，从而导致梯度消失，因此还需要对点乘结果进行一定的缩放，通常采用的系数是 <script type="math/tex">\frac{1}{\sqrt{D_k}}</script>。</li>
<li>第三步，对缩放后的注意力分数进行归一化，通常采用 softmax 函数进行归一化，保证最终该 token 注意力分数之和为 1，相当于转换成概率。</li>
<li>最后，将归一化后的注意力分数与其对应的 token 相乘并求和，最终得到包含自身与上下文的向量表示。</li>
<li>整个过程可以这样理解：Q 矩阵是我们需要查询的东西，K 矩阵是 token 自身的关键词和关键信息，通过 Q 与 K 相乘，就可以得到每个 token 与我们所需要查询的东西的相关度，相关度越高我们就越需要关注它。V 矩阵是每个 token 实际的含义，我们根据先前计算得到的关注度进行加权求和，最终得到的结果就包含了自身和相关上下文的信息。</li>
</ul>
<h4 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h4><p class='item-img' data-src='../../images/Transformer/2.png'><img src="../../images/Transformer/2.png" alt=""></p>
<ul>
<li><p>如果仅仅为一个 token 线性投影出一份 Q、K、V 矩阵，那多个语义子空间的信息就被平均化了，模型就很难关注来自不同语义子空间的信息。以看电影为例，如果是 Self Attention，我们只能整体评价一部电影好还是不好，但如果采用 Multi-Head Attention，那我们就可以从不同的方面，如音乐、画面等，对电影进行评价。</p>
</li>
<li><p>具体做法就是每个 token 线性投影得到 h 个 Q、K、V 矩阵，每一组都进行 Self Attention，得到的注意力分数矩阵 Z 拼接在一起，最终与一个可学习的权重矩阵相乘，统合各个语义子空间的信息，使最终的结果维度与输入的词向量相同。</p>
</li>
</ul>
<h4 id="Cross-Attention"><a href="#Cross-Attention" class="headerlink" title="Cross Attention"></a>Cross Attention</h4><h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><div id="paginator"></div></div><div id="post-footer"><div id="pages"><div class="footer-link" style="width: 50%;text-align:right;border-right:1px #fe2 solid"><a href="/2025/09/24/Embedding/RoPE/">← Next RoPE</a></div><div class="footer-link" style="width: 50%;right:1px;border-left:1px #fe2 solid"><a href="/2025/09/24/NeuralNetwork/RNN%E3%80%81LSTM%E5%92%8CGRU/">RNN、LSTM和GRU Prev →</a></div></div></div></div><div class="bottom-btn"><div><a class="i-top" id="to-top" onClick="scrolls.scrolltop();" title="To Top" style="opacity: 0; display: none;">∧ </a><a class="i-index" id="to-index" href="#toc-div" title="To Catalog">≡</a><a class="i-color" id="color-mode" onClick="colorMode.change()" title="Change Theme"></a><a onclick="BgmControl()"><svg id="bgm-control" viewBox="0 0 30 34" fill="#18d1ff" style="width: 24px; transition: transform .3s;margin-top: 4px"><path d="M25.998 23.422V11.29h3.999v12.132h-3.999zM19.497 6.234h4.001v22.243h-4.001V6.234zM12.998.867h4v32.978h-4V.867zm-6.5 5.367h4.001v22.243H6.498V6.234zm-6.5 5.056h4v12.132h-4V11.29z"></path></svg><audio id="bgm" src="/audio/bgm.mp3" autoplay loop crossorigin="anonymous"> </audio></a></div></div></article><aside><div id="about"><a href="/" id="logo"><img src="https://ak.hypergryph.com/assets/index/images/ak/pc/faction/1.png" alt="Logo" style="margin:0;border-radius:0;"></a><h1 id="Dr"><a href="/">Kamikit</a></h1><div id="description"><p></p></div></div><div id="aside-block"><div id="toc-div"><h1>Catalog</h1><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Attention"><span class="toc-number">1.</span> <span class="toc-text">Attention</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Self-Attention"><span class="toc-number">1.1.</span> <span class="toc-text">Self Attention</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Multi-Head-Attention"><span class="toc-number">1.2.</span> <span class="toc-text">Multi-Head Attention</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Cross-Attention"><span class="toc-number">1.3.</span> <span class="toc-text">Cross Attention</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text"> </span></a></li></ol></div></div><footer><nobr>Published with <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a></nobr><wbr><nobr> Theme <a target="_blank" rel="noopener" href="https://github.com/Yue-plus/hexo-theme-arknights">Arknights</a></nobr><wbr><nobr> by <a target="_blank" rel="noopener" href="https://github.com/Yue-plus">Yue_plus</a></nobr></footer></aside></main><canvas id="canvas-dust"></canvas></body></html>